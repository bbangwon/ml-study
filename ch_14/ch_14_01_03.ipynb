{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659bf231",
   "metadata": {},
   "source": [
    "# 데이터 전처리와 스케일 조정\n",
    "\n",
    "- 데이터를 모델링하기 전에는 반드시 스케일링 과정을 거쳐야 함\n",
    "- 스케일링을 통해 다차원의 값들을 비교 분석하기 쉽게 만들어 줌\n",
    "- 자료의 오버플로우(overflow)나 언더플로우(underflow)를 방지\n",
    "- 독립 변수의 공분산 행렬의 조건수(condition number)를 감소시켜 최적화 과정에서의 안정성 및 수렴 속도를 향상\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff38e086",
   "metadata": {},
   "source": [
    "- StandardScaler\n",
    "  - 각 특성의 평균을 0, 분산을 1로 변경하여 특성의 스케일을 맞춤\n",
    "  - 최솟값과 최댓값의 크기를 제한하지 않음\n",
    "- RobustScaler\n",
    "  - 평균과 분산 대신에 중간값과 사분위 값을 사용함\n",
    "  - 중간값은 정렬시 중간에 있는 값을 의미하고, 사분위값은 1/4, 3/4에 위치한 값을 의미함\n",
    "  - 전체 데이터와 아주 동떨어진 데이터 포인트(이상치)에 영향을 받지 않음\n",
    "- MinMaxScaler\n",
    "  - 모든 특성이 0과 1 사이에 위치하도록 데이터를 변경함\n",
    "- Normalizer\n",
    "  - 위와 다른 스케일 조정법으로 특성 벡터의 유클리디안 길이가 1이 되도록 조정함\n",
    "  - 즉 길이가 1인 원 또는 구로 투영하는 것이고, 각도만이 중요할 때 적용함\n",
    "  - l1, l2, max 옵션을 제공하며 유클리디안 거리인 l2가 기본값임\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d350f0",
   "metadata": {},
   "source": [
    "# 주가 데이터를 정규화하기\n",
    "\n",
    "- 사이킷런(scikit-learn)\n",
    "  - 파이썬에서 머신러닝 분석을 위해 사용할 수 있는 라이브러리\n",
    "  - 머신러닝을 위한 다양한 알고리즘과 개발을 위한 편리한 프레임워크, API를 제공\n",
    "- sklearn 패키지에 있는 MinMaxScaler를 활용하여 전체 학습 데이터를 Normalize 해주기\n",
    "  - MinMaxScaler를 해주면 전체 데이터는 0, 1사이의 값을 갖게 됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11fd7434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yfin\n",
    "from pandas_datareader import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e17cfb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bbang\\AppData\\Local\\Temp\\ipykernel_22176\\1026581699.py:1: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_price = yfin.download(\"NVDA\", start=\"2023-01-01\", end=\"2024-05-28\")\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df_price = yfin.download(\"NVDA\", start=\"2023-01-01\", end=\"2024-05-28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980eb69f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th></th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "      <th>NVDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>14.302286</td>\n",
       "      <td>14.982682</td>\n",
       "      <td>14.083481</td>\n",
       "      <td>14.837810</td>\n",
       "      <td>401277000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>14.735900</td>\n",
       "      <td>14.839808</td>\n",
       "      <td>14.228352</td>\n",
       "      <td>14.554062</td>\n",
       "      <td>431324000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>14.252334</td>\n",
       "      <td>14.551068</td>\n",
       "      <td>14.135437</td>\n",
       "      <td>14.478133</td>\n",
       "      <td>389168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>14.845802</td>\n",
       "      <td>14.996668</td>\n",
       "      <td>14.021535</td>\n",
       "      <td>14.461144</td>\n",
       "      <td>405044000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>15.614120</td>\n",
       "      <td>16.041739</td>\n",
       "      <td>15.127552</td>\n",
       "      <td>15.270425</td>\n",
       "      <td>504231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2024-05-20</td>\n",
       "      <td>94.742279</td>\n",
       "      <td>95.162110</td>\n",
       "      <td>93.402816</td>\n",
       "      <td>93.712690</td>\n",
       "      <td>318764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2024-05-21</td>\n",
       "      <td>95.348045</td>\n",
       "      <td>95.362040</td>\n",
       "      <td>93.142922</td>\n",
       "      <td>93.561754</td>\n",
       "      <td>328946000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2024-05-22</td>\n",
       "      <td>94.912224</td>\n",
       "      <td>95.981798</td>\n",
       "      <td>93.211904</td>\n",
       "      <td>95.421024</td>\n",
       "      <td>548648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>103.757698</td>\n",
       "      <td>106.277691</td>\n",
       "      <td>101.479598</td>\n",
       "      <td>101.987399</td>\n",
       "      <td>835065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>106.426636</td>\n",
       "      <td>106.432630</td>\n",
       "      <td>102.959014</td>\n",
       "      <td>104.407435</td>\n",
       "      <td>429494000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price        Date       Close        High         Low        Open     Volume\n",
       "Ticker                   NVDA        NVDA        NVDA        NVDA       NVDA\n",
       "0      2023-01-03   14.302286   14.982682   14.083481   14.837810  401277000\n",
       "1      2023-01-04   14.735900   14.839808   14.228352   14.554062  431324000\n",
       "2      2023-01-05   14.252334   14.551068   14.135437   14.478133  389168000\n",
       "3      2023-01-06   14.845802   14.996668   14.021535   14.461144  405044000\n",
       "4      2023-01-09   15.614120   16.041739   15.127552   15.270425  504231000\n",
       "..            ...         ...         ...         ...         ...        ...\n",
       "346    2024-05-20   94.742279   95.162110   93.402816   93.712690  318764000\n",
       "347    2024-05-21   95.348045   95.362040   93.142922   93.561754  328946000\n",
       "348    2024-05-22   94.912224   95.981798   93.211904   95.421024  548648000\n",
       "349    2024-05-23  103.757698  106.277691  101.479598  101.987399  835065000\n",
       "350    2024-05-24  106.426636  106.432630  102.959014  104.407435  429494000\n",
       "\n",
       "[351 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price.reset_index(inplace=True)\n",
    "df_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b876c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.18768049e-03, 4.69750523e-03, 6.96506287e-04, 5.41935289e-04,\n",
       "        1.50901165e-01],\n",
       "       [1.03304233e-03, 3.14252078e-03, 2.32541363e-03, 5.24621584e-03,\n",
       "        1.73229289e-01],\n",
       "       [1.88876673e-04, 0.00000000e+00, 1.28069385e-03, 0.00000000e+00,\n",
       "        1.41902888e-01],\n",
       "       ...,\n",
       "       [9.00091364e-01, 8.86257569e-01, 8.90404919e-01, 8.75080021e-01,\n",
       "        2.60413524e-01],\n",
       "       [9.73094653e-01, 9.98313708e-01, 9.83365659e-01, 9.71044666e-01,\n",
       "        4.73251879e-01],\n",
       "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "        1.71869403e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scale_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
    "df_scaled = scaler.fit_transform(df_price[scale_cols])\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3acc77a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.150901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.173229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.153700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008997</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>0.014774</td>\n",
       "      <td>0.227407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>0.881099</td>\n",
       "      <td>0.877336</td>\n",
       "      <td>0.892552</td>\n",
       "      <td>0.873236</td>\n",
       "      <td>0.089585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0.879420</td>\n",
       "      <td>0.879512</td>\n",
       "      <td>0.889629</td>\n",
       "      <td>0.879808</td>\n",
       "      <td>0.097152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.900091</td>\n",
       "      <td>0.886258</td>\n",
       "      <td>0.890405</td>\n",
       "      <td>0.875080</td>\n",
       "      <td>0.260414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.973095</td>\n",
       "      <td>0.998314</td>\n",
       "      <td>0.983366</td>\n",
       "      <td>0.971045</td>\n",
       "      <td>0.473252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.171869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Open      High       Low     Close    Volume\n",
       "0    0.004188  0.004698  0.000697  0.000542  0.150901\n",
       "1    0.001033  0.003143  0.002325  0.005246  0.173229\n",
       "2    0.000189  0.000000  0.001281  0.000000  0.141903\n",
       "3    0.000000  0.004850  0.000000  0.006439  0.153700\n",
       "4    0.008997  0.016224  0.012436  0.014774  0.227407\n",
       "..        ...       ...       ...       ...       ...\n",
       "346  0.881099  0.877336  0.892552  0.873236  0.089585\n",
       "347  0.879420  0.879512  0.889629  0.879808  0.097152\n",
       "348  0.900091  0.886258  0.890405  0.875080  0.260414\n",
       "349  0.973095  0.998314  0.983366  0.971045  0.473252\n",
       "350  1.000000  1.000000  1.000000  1.000000  0.171869\n",
       "\n",
       "[351 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = pd.DataFrame(df_scaled)\n",
    "df_scaled.columns = scale_cols\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea6c9ae",
   "metadata": {},
   "source": [
    "# 학습 데이터셋과 테스트 데이터셋 생성하기\n",
    "\n",
    "- TEST_SIZE=30\n",
    "  - 학습은 과거부터 30일 이전의 데이터를 학습하게 되고, TEST를 위해서 이후 30일의 데이터로 모델이 주가를 예측하도록 한 다음, 실제 데이터와 오차가 얼마나 있는지 확인해보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2c54d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 30\n",
    "train = df_scaled[:-TEST_SIZE]\n",
    "test = df_scaled[-TEST_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe7bbb",
   "metadata": {},
   "source": [
    "- dataset을 만들어 주는 함수\n",
    "- 정해진 window_size에 기반하여 5일 기간의 데이터셋을 묶어 주는 역할을 하는 함수\n",
    "- 순차적으로 5일 동안의 데이터셋을 묶고, 이에 맞는 label(예측 데이터)와 함께 return해 줌\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc7122d",
   "metadata": {},
   "source": [
    "- window_size\n",
    "  - 얼마 동안(기간)의 주가 데이터에 기반하여 다음날 종가를 예측할 것인가를 정하는 parameter\n",
    "  - 과거 5일을 기반으로 내일 데이터를 예측한다라고 가정했을 때, window_size=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f8b9f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data, label, window_size=5):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        feature_list.append(np.array(data.iloc[i : i + window_size]))\n",
    "        label_list.append(np.array(label.iloc[i + window_size]))\n",
    "    return np.array(feature_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4176553",
   "metadata": {},
   "source": [
    "- feature와 label 정의하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65fa0f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\"Open\", \"High\", \"Low\", \"Volume\"]\n",
    "label_cols = [\"Close\"]\n",
    "\n",
    "train_feature = train[feature_cols]\n",
    "train_label = train[label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46ee2799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "train_feature, train_label = make_dataset(train_feature, train_label, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d743d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, validation set 생성\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa052213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((252, 5, 4), (64, 5, 4))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    train_feature, train_label, test_size=0.2\n",
    ")\n",
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2567e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 5, 4), (25, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_dataset\n",
    "test_feature = test[feature_cols]\n",
    "test_label = test[label_cols]\n",
    "\n",
    "# test dataset (실제 예측해 볼 데이터)\n",
    "test_feature, test_label = make_dataset(test_feature, test_label, 5)\n",
    "test_feature.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a7f25",
   "metadata": {},
   "source": [
    "# keras를 활용한 LSTM 모델 생성\n",
    "\n",
    "- 텐서플로우\n",
    "  - 구글에서 개발하고 오픈소스로 공개한 머신러닝 라이브러리, 내부 구조 확인 디버거 사용\n",
    "- 모델 학습을 시켜보고 evaluation 해보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b24cc7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f00c40",
   "metadata": {},
   "source": [
    "- Sequential() 메서드\n",
    "  - 케라스에서는 인공신경망의 입력층, 은닉층, 출력층을 구성하기 위해 Sequential()을 사용\n",
    "  - Sequential()을 model로 선언한 뒤에 model.add()라는 코드를 통해 층을 단계적으로 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba743b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(train_feature.shape[1], train_feature.shape[2])))\n",
    "model.add(\n",
    "    LSTM(\n",
    "        16,\n",
    "        activation=\"relu\",\n",
    "        return_sequences=False,\n",
    "    )\n",
    ")\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a365fa34",
   "metadata": {},
   "source": [
    "- Dense() 메서드 예시\n",
    "  - 전결합층(fully-connected layer)\n",
    "    - 첫번째 인자 = 출력 뉴런의 수\n",
    "    - input_dim = 입력 뉴런의 수(입력의 차원)\n",
    "    - activation = 활성화 함수\n",
    "      -relu: 은닉층에 주로 사용되는 활성화 함수\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b212e41",
   "metadata": {},
   "source": [
    "- summary() 메서드\n",
    "  - 모델의 정보를 요약해서 보여줌\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37c16c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,344</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,344\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,361</span> (5.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,361\u001b[0m (5.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,361</span> (5.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,361\u001b[0m (5.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb40a5",
   "metadata": {},
   "source": [
    "# 모델의 학습\n",
    "\n",
    "- compile()\n",
    "  - 모델을 기계가 이해할 수 있도록 컴파일 함\n",
    "  - 손실 함수와 옵티마이저, 메트릭 함수를 선택함\n",
    "  - optimizer = 훈련 과정을 설정하는 옵티마이저를 설정\n",
    "  - loss = 훈련 과정에서 사용할 손실 함수(loss function)를 설정\n",
    "  - metrics = 훈련을 모니터링하기 위한 지표를 선택\n",
    "    | 문제 유형 | 손실 함수명 | 출력층의 활성화 함수 명 |\n",
    "    | -- | -- | -- |\n",
    "    | 회귀 문제 | mean_squared_error | - |\n",
    "    | 다중 클래스 분류 | categorical_crossentropy | 소프트맥스 |\n",
    "    | 다중 클래스 분류 | sparse_catogorical_crossentropy | 소프트맥스 |\n",
    "    | 이진 분류 | binary_crossentropy | 시그모이드 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c5cbf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\", patience=5)\n",
    "filename = \"tmp_checkpoint.h5.keras\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filename, monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a30eca",
   "metadata": {},
   "source": [
    "- fit()\n",
    "  - 모델을 학습\n",
    "  - 모델이 오차로부터 매개 변수를 업데이트 시키는 과정을 학습, 훈련, 또는 적합(fitting)이라고 하는데, 모델이 데이터에 적합해가는 과정이기 때문\n",
    "  - 첫번째 인자 = 학습 데이터,\n",
    "  - 두번째 인자 = 지도 학습에서 레이블 데이터\n",
    "  - epochs = 에포크\n",
    "    - 에포크 1은 전체 데이터를 한 차례 훝고 지나갔음을 의미함\n",
    "    - 정수값 기재, 총 학습 횟수를 정의함\n",
    "  - batch_size = 배치크기\n",
    "    - 기본값은 32, 미니 배치 경사 하강법을 사용하고 싶지 않을 경우에는 batch_size=None을 기재\n",
    "  - validation_data(x_val, y_val) = 검증 데이터(validation data)를 사용함\n",
    "    - 일반적으로 검증 데이터를 사용하면 각 에포크마다 검증 데이터의 정확도나 오차를 함께 출력하는데, 이 정확도는 학습이 잘 되고 있는지를 보여줄 뿐이며 실제로 모델이 검증 데이터를 학습하지는 않음\n",
    "    - 검증 데이터의 오차가 낮아지다가 높아지기 시작하면 과적합의 신호\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7d3ab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 700ms/step - loss: 0.1255\n",
      "Epoch 1: val_loss improved from None to 0.05304, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0955 - val_loss: 0.0530\n",
      "Epoch 2/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0654\n",
      "Epoch 2: val_loss improved from 0.05304 to 0.01720, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0459 - val_loss: 0.0172\n",
      "Epoch 3/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0440\n",
      "Epoch 3: val_loss improved from 0.01720 to 0.00385, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0133 - val_loss: 0.0038\n",
      "Epoch 4/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0067\n",
      "Epoch 4: val_loss improved from 0.00385 to 0.00260, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 5/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0024\n",
      "Epoch 5: val_loss improved from 0.00260 to 0.00102, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0011\n",
      "Epoch 6: val_loss improved from 0.00102 to 0.00093, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.5264e-04 - val_loss: 9.2758e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 6.6806e-04\n",
      "Epoch 7: val_loss improved from 0.00093 to 0.00083, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.9066e-04 - val_loss: 8.3103e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7.5921e-04\n",
      "Epoch 8: val_loss improved from 0.00083 to 0.00077, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.0922e-04 - val_loss: 7.7059e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.0524e-04\n",
      "Epoch 9: val_loss improved from 0.00077 to 0.00070, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.5456e-04 - val_loss: 7.0165e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4.5494e-04\n",
      "Epoch 10: val_loss did not improve from 0.00070\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9183e-04 - val_loss: 7.4269e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.5843e-04\n",
      "Epoch 11: val_loss did not improve from 0.00070\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9178e-04 - val_loss: 7.3666e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.4308e-04\n",
      "Epoch 12: val_loss did not improve from 0.00070\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.6959e-04 - val_loss: 7.0699e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.4510e-04\n",
      "Epoch 13: val_loss improved from 0.00070 to 0.00069, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.6717e-04 - val_loss: 6.9038e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9.3961e-04\n",
      "Epoch 14: val_loss improved from 0.00069 to 0.00067, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.5959e-04 - val_loss: 6.6908e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.6949e-04\n",
      "Epoch 15: val_loss did not improve from 0.00067\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.4662e-04 - val_loss: 6.9763e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.7518e-04\n",
      "Epoch 16: val_loss improved from 0.00067 to 0.00064, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4414e-04 - val_loss: 6.3764e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 3.8127e-04\n",
      "Epoch 17: val_loss did not improve from 0.00064\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.3833e-04 - val_loss: 6.5875e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9.0246e-05\n",
      "Epoch 18: val_loss did not improve from 0.00064\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3408e-04 - val_loss: 6.3798e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.6819e-04\n",
      "Epoch 19: val_loss did not improve from 0.00064\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.2736e-04 - val_loss: 6.6600e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.9059e-04\n",
      "Epoch 20: val_loss improved from 0.00064 to 0.00060, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1784e-04 - val_loss: 6.0416e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.0603e-04\n",
      "Epoch 21: val_loss did not improve from 0.00060\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.2210e-04 - val_loss: 6.7258e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 9.4480e-04\n",
      "Epoch 22: val_loss did not improve from 0.00060\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1710e-04 - val_loss: 6.5544e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.4696e-04\n",
      "Epoch 23: val_loss improved from 0.00060 to 0.00060, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.0147e-04 - val_loss: 6.0403e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6.4108e-04\n",
      "Epoch 24: val_loss improved from 0.00060 to 0.00058, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1116e-04 - val_loss: 5.8082e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 8.1651e-04\n",
      "Epoch 25: val_loss did not improve from 0.00058\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.4645e-04 - val_loss: 7.7752e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7.0401e-04\n",
      "Epoch 26: val_loss did not improve from 0.00058\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3217e-04 - val_loss: 5.9680e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4.7176e-04\n",
      "Epoch 27: val_loss did not improve from 0.00058\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.9196e-04 - val_loss: 6.6589e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 3.8472e-04\n",
      "Epoch 28: val_loss improved from 0.00058 to 0.00054, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8883e-04 - val_loss: 5.4384e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 2.1812e-04\n",
      "Epoch 29: val_loss did not improve from 0.00054\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.8386e-04 - val_loss: 7.6284e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 8.7427e-04\n",
      "Epoch 30: val_loss did not improve from 0.00054\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1660e-04 - val_loss: 5.7739e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.3658e-04\n",
      "Epoch 31: val_loss improved from 0.00054 to 0.00053, saving model to tmp_checkpoint.h5.keras\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.9103e-04 - val_loss: 5.3032e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.9553e-04\n",
      "Epoch 32: val_loss did not improve from 0.00053\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7897e-04 - val_loss: 6.3623e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.1755e-04\n",
      "Epoch 33: val_loss did not improve from 0.00053\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7040e-04 - val_loss: 5.5902e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5.1277e-04\n",
      "Epoch 34: val_loss did not improve from 0.00053\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.6792e-04 - val_loss: 5.4657e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.5107e-04\n",
      "Epoch 35: val_loss did not improve from 0.00053\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.7139e-04 - val_loss: 5.3523e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m 1/16\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.0108e-04\n",
      "Epoch 36: val_loss did not improve from 0.00053\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.5520e-04 - val_loss: 6.1806e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=200,\n",
    "    batch_size=16,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks=[early_stop, checkpoint],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-study (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
