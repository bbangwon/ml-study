{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe93f62",
   "metadata": {},
   "source": [
    "# 데이터 분석 알고리즘\n",
    "\n",
    "- 데이터 분석 알고리즘\n",
    "  - 머신러닝/딥러닝 분야에서 딥러닝 다음으로 부스팅(boosting) 알고리즘이 핵심적으로 사용됨\n",
    "  - 선형회귀나 로지스틱 회귀는 가장 대중적인 알고리즘이고, 그 다음이 의사결정트리와 앙상블 계열 알고리즘, 딥러닝\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ab2dc",
   "metadata": {},
   "source": [
    "# 앙상블의 개념\n",
    "\n",
    "- 앙상블(ensemble)\n",
    "  - 여러 개의 알고리즘들이 하나의 값을 예측하는 기법을 통칭하여 말함\n",
    "  - 회귀 문제에서는 가중 평균이나 단순 평균을 구하는 방식으로 Y값을 예측\n",
    "- 메타 분류기(meta-classifier)라고도 부름\n",
    "  - 메타(meta)는 일종의 상위 또는 추상화라는 개념\n",
    "  - 여러 분류기들을 모아 하나의 분류기를 만들어 이를 메타 분류기라고 부름\n",
    "- 시간이 굉장히 오래 걸리지만 비교적 좋은 성능을 냄\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f37c6",
   "metadata": {},
   "source": [
    "- 하나의 데이터를 넣음\n",
    "  - 이를 여러 모델에 학습시키고\n",
    "  - 테스트 데이터를 각 모델에 입력\n",
    "  - 투표 또는 여러 가중치 기법을 적용하여 최종 선택\n",
    "- 바닐라 앙상블\n",
    "  - 가장 기본적인 앙상블 기법, 아무것도 처리하지 않은 앙상블 모델을 의미\n",
    "  - 일반적으로 가중치 평균이나 투표 방식으로 만들어지는 앙상블 모델\n",
    "- 부스팅\n",
    "  - 하나의 모델에서 여러 데이터를 샘플링한 다음 그 샘플링된 데이터로 각각의 모델을 만드는 기법\n",
    "- 배깅\n",
    "  - boosting aggregation(부스팅 집합)의 줄임말로 부스팅을 좀 더 발전시킨 기법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08687465",
   "metadata": {},
   "source": [
    "# 투표 분류기의 개념\n",
    "\n",
    "- 투표 분류기(voting classifier)\n",
    "  - 여러 개의 모델을 만들어 모두 같은 데이터를 넣고 결과를 취합하여 가장 많이 선택된 결과를 취함\n",
    "  - 앙상블 모델의 가장 기본적인 형태\n",
    "  - 다수결 분류기(majority voting classifier)라고도 부름\n",
    "  - 또는 각 분류기마다 가중치를 주고 해당 가중치를 각 모델에 곱하여 가중치의 합을 구하는 방식\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf56ed",
   "metadata": {},
   "source": [
    "# 투표 분류기의 클래스\n",
    "\n",
    "- 투표 분류기의 클래스\n",
    "  - 사이킷런에서 제공하는 VotingClassifier 클래스 사용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2232c43",
   "metadata": {},
   "source": [
    "#### 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0603481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "\n",
    "def transform_status(x):\n",
    "    if \"Mrs\" in x or \"Ms\" in x:\n",
    "        return \"Mrs\"\n",
    "    elif \"Mr\" in x:\n",
    "        return \"Mr\"\n",
    "    elif \"Miss\" in x:\n",
    "        return \"Miss\"\n",
    "    elif \"Master\" in x:\n",
    "        return \"Master\"\n",
    "    elif \"Dr\" in x:\n",
    "        return \"Dr\"\n",
    "    elif \"Rev\" in x:\n",
    "        return \"Rev\"\n",
    "    elif \"Col\" in x:\n",
    "        return \"Col\"\n",
    "    else:\n",
    "        return \"0\"\n",
    "\n",
    "\n",
    "train_df = pd.read_csv(\"./titanic/train.csv\")\n",
    "test_df = pd.read_csv(\"./titanic/test.csv\")\n",
    "\n",
    "train_id = train_df[\"PassengerId\"].values\n",
    "test_id = test_df[\"PassengerId\"].values\n",
    "\n",
    "all_df = pd.concat([train_df, test_df]).set_index(\"PassengerId\")\n",
    "all_df[\"Sex\"] = all_df[\"Sex\"].replace({\"male\": 0, \"female\": 1}).astype(int)\n",
    "all_df[\"Age\"] = all_df[\"Age\"].fillna(all_df.groupby(\"Pclass\")[\"Age\"].transform(\"mean\"))\n",
    "all_df[\"cabin_count\"] = all_df[\"Cabin\"].map(\n",
    "    lambda x: len(x.split()) if type(x) == str else 0\n",
    ")\n",
    "all_df[\"social_status\"] = all_df[\"Name\"].map(lambda x: transform_status(x))\n",
    "all_df = all_df.drop([62, 830])\n",
    "train_id = np.delete(train_id, [62 - 1, 830 - 1])\n",
    "all_df.loc[all_df[\"Fare\"].isnull(), \"Fare\"] = 12.415462\n",
    "all_df[\"cabin_type\"] = all_df[\"Cabin\"].map(lambda x: x[0] if type(x) == str else \"99\")\n",
    "\n",
    "del all_df[\"Cabin\"]\n",
    "del all_df[\"Name\"]\n",
    "del all_df[\"Ticket\"]\n",
    "\n",
    "y = all_df.loc[train_id, \"Survived\"].values\n",
    "del all_df[\"Survived\"]\n",
    "\n",
    "X_df = pd.get_dummies(all_df)\n",
    "X = X_df.values\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "minmax_scaler.fit(X)\n",
    "X = minmax_scaler.transform(X)\n",
    "\n",
    "X_train = X[: len(train_id)]\n",
    "X_test = X[len(train_id) :]\n",
    "\n",
    "np.save(\"./titanic/titanic_X_train.npy\", X_train)\n",
    "np.save(\"./titanic/titanic_y_train.npy\", y)\n",
    "np.save(\"./titanic/titanic_test.npy\", X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd3a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b7b76",
   "metadata": {},
   "source": [
    "- 전처리되어 .npy 파일 형태인 데이터를 호출\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcb29efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"./titanic/titanic_X_train.npy\")\n",
    "y = np.load(\"./titanic/titanic_y_train.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cb357356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.27345609, 0.125     , 0.        ,\n",
       "       0.01415106, 0.        , 0.        , 0.        , 1.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2f5fd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 0., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcfed5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = DecisionTreeClassifier(random_state=1, max_depth=4)\n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[(\"lr\", clf1), (\"rf\", clf2), (\"gnb\", clf3)], voting=\"hard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81f07b6",
   "metadata": {},
   "source": [
    "# 투표 분류기의 클래스\n",
    "\n",
    "- 투표 분류기의 클래스\n",
    "  - 투표 분류기의 성능과 모델별 성능을 측정\n",
    "  - clf3 제외하면 전체 모델 성능보다 개별 모델 성능이 높음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eed1c2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8222941661905668)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(eclf, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbbb15eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8290420872214816)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf1, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1583512c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8223068621849807)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf2, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7020e5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4600139655938551)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf3, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e599495",
   "metadata": {},
   "source": [
    "# 투표 분류기의 클래스\n",
    "\n",
    "- 투표 분류기의 클래스\n",
    "  - GaussianNB는 연속적인 데이터를 다루기 위한 모델로 데이터셋과 맞지 않아 해당 모델을 빼고 성능을 측정\n",
    "  - 앙상블 모델에서는 반드시 많은 수의 모델 조합이 가장 최선의 결과를 내는 것은 아님\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "51035ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8301783787215135)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf = VotingClassifier(estimators=[(\"lr\", clf1), (\"rf\", clf2)], voting=\"hard\")\n",
    "cross_val_score(eclf, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef3d8d",
   "metadata": {},
   "source": [
    "# 하이퍼 매개변수를 튜닝한 투표 분류기\n",
    "\n",
    "- 하이퍼 매개변수를 튜닝한 투표 분류기\n",
    "  - 성능이 좋았던 모델 두 개를 각각 VotingClassifier에 할당\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab9c3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = DecisionTreeClassifier(random_state=1)\n",
    "eclf = VotingClassifier(estimators=[(\"lr\", clf1), (\"dt\", clf2)], voting=\"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "581486e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_params = [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]\n",
    "\n",
    "params = {\n",
    "    \"lr__solver\": [\"liblinear\"],\n",
    "    \"lr__penalty\": [\"l2\"],\n",
    "    \"lr__C\": c_params,\n",
    "    \"dt__criterion\": [\"gini\", \"entropy\"],\n",
    "    \"dt__max_depth\": [10, 8, 7, 6, 5, 4, 3, 2],\n",
    "    \"dt__min_samples_leaf\": [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b355704",
   "metadata": {},
   "source": [
    "- 가장 좋은 모델의 성능을 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0604568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8425569732749316)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, cv=5)\n",
    "grid = grid.fit(X, y)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6099145c",
   "metadata": {},
   "source": [
    "- 가장 좋은 성능을 내는 매개변수 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60272051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__criterion': 'gini',\n",
       " 'dt__max_depth': 10,\n",
       " 'dt__min_samples_leaf': 5,\n",
       " 'lr__C': 5.0,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__solver': 'liblinear'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-study (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
